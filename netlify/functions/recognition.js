import axios from 'axios';

// åˆ›å»ºä¸“ç”¨çš„axioså®ä¾‹ï¼Œç¡®ä¿åœ¨Netlifyç¯å¢ƒä¸­ä¸ä½¿ç”¨ä»£ç†
const createAxiosInstance = () => {
  const config = {
    timeout: 60000, // 60ç§’è¶…æ—¶
    maxRedirects: 5
  };
  
  // åœ¨Netlifyç¯å¢ƒä¸­æ˜ç¡®ç¦ç”¨ä»£ç†
  if (process.env.NETLIFY || process.env.CONTEXT || process.env.DEPLOY_URL || process.env.NETLIFY_DEV) {
    config.proxy = false;
    console.log('ğŸš« Netlify environment detected - all proxy disabled');
  }
  
  return axios.create(config);
};

const axiosInstance = createAxiosInstance();

// è¯†åˆ«ç±»å‹å’Œå¯¹åº”çš„æç¤ºè¯
const RECOGNITION_PROMPTS = {
  auto: 'è¯·åˆ†æè¿™å¼ å›¾ç‰‡ï¼Œè‡ªåŠ¨è¯†åˆ«å…¶ç±»å‹ï¼ˆå¦‚æ–‡æ¡£ã€æ”¶æ®ã€å¤ç±ã€è¯ä»¶ç­‰ï¼‰ï¼Œå¹¶æå–ç›¸å…³ä¿¡æ¯ã€‚',
  ancient: 'è¯·è¯†åˆ«è¿™å¼ å¤ç±æˆ–å¤æ–‡å­—å›¾ç‰‡ä¸­çš„æ–‡å­—å†…å®¹ï¼Œä¿æŒåŸæ–‡æ ¼å¼ï¼Œå¹¶æä¾›ç°ä»£æ–‡å­—çš„å¯¹åº”ç¿»è¯‘ã€‚',
  receipt: 'è¯·è¯†åˆ«è¿™å¼ æ”¶æ®æˆ–å‘ç¥¨ä¸­çš„å…³é”®ä¿¡æ¯ï¼ŒåŒ…æ‹¬å•†å®¶åç§°ã€æ—¥æœŸã€é‡‘é¢ã€å•†å“æ¸…å•ç­‰ã€‚',
  document: 'è¯·è¯†åˆ«è¿™å¼ æ–‡æ¡£å›¾ç‰‡ä¸­çš„æ‰€æœ‰æ–‡å­—å†…å®¹ï¼Œä¿æŒåŸæœ‰æ ¼å¼å’Œç»“æ„ã€‚',
  id: 'è¯·è¯†åˆ«è¿™å¼ è¯ä»¶å›¾ç‰‡ä¸­çš„ä¿¡æ¯ï¼ŒåŒ…æ‹¬å§“åã€è¯ä»¶å·ç ã€æœ‰æ•ˆæœŸç­‰å…³é”®ä¿¡æ¯ã€‚',
  table: 'è¯·è¯†åˆ«è¿™å¼ è¡¨æ ¼æˆ–å›¾è¡¨ä¸­çš„æ•°æ®ï¼Œä»¥ç»“æ„åŒ–çš„æ–¹å¼å±•ç¤ºå†…å®¹ã€‚',
  handwriting: 'è¯·è¯†åˆ«è¿™å¼ æ‰‹å†™æ–‡å­—å›¾ç‰‡ä¸­çš„å†…å®¹ï¼Œå°½å¯èƒ½å‡†ç¡®åœ°è½¬æ¢ä¸ºæ–‡æœ¬ã€‚',
  prompt: 'è¯·ä¸ºè¿™å¼ å›¾ç‰‡ç”Ÿæˆè¯¦ç»†çš„AIç»˜å›¾æç¤ºè¯ï¼ŒåŒ…æ‹¬é£æ ¼ã€è‰²å½©ã€æ„å›¾ç­‰è¦ç´ ã€‚'
};

export const handler = async (event, context) => {
  // è®¾ç½®CORSå¤´
  const headers = {
    'Access-Control-Allow-Origin': '*',
    'Access-Control-Allow-Headers': 'Content-Type, Authorization',
    'Access-Control-Allow-Methods': 'POST, OPTIONS',
    'Content-Type': 'application/json'
  };

  if (event.httpMethod === 'OPTIONS') {
    return {
      statusCode: 200,
      headers,
      body: ''
    };
  }

  if (event.httpMethod !== 'POST') {
    return {
      statusCode: 405,
      headers,
      body: JSON.stringify({ error: 'Method not allowed' })
    };
  }

  try {
    const { fileId, imageUrl, modelConfig, recognitionType = 'auto' } = JSON.parse(event.body);

    // éªŒè¯å¿…è¦å‚æ•°
    if (!fileId && !imageUrl) {
      return {
        statusCode: 400,
        headers,
        body: JSON.stringify({
          error: 'Missing fileId or imageUrl',
          message: 'è¯·æä¾›æ–‡ä»¶IDæˆ–å›¾ç‰‡URL'
        })
      };
    }

    if (!modelConfig || !modelConfig.model || !modelConfig.apiKey) {
      return {
        statusCode: 400,
        headers,
        body: JSON.stringify({
          error: 'Invalid model config',
          message: 'è¯·æä¾›å®Œæ•´çš„æ¨¡å‹é…ç½®ï¼ˆæ¨¡å‹åç§°å’ŒAPIå¯†é’¥ï¼‰'
        })
      };
    }

    console.log(`ğŸ” å¼€å§‹è¯†åˆ«å›¾ç‰‡: ${fileId || imageUrl}`);
    console.log(`ğŸ“‹ è¯†åˆ«ç±»å‹: ${recognitionType}`);
    console.log(`ğŸ¤– ä½¿ç”¨æ¨¡å‹: ${modelConfig.model}`);

    // è·å–è¯†åˆ«æç¤ºè¯
    const prompt = RECOGNITION_PROMPTS[recognitionType] || RECOGNITION_PROMPTS.auto;

    // è°ƒç”¨AIæ¨¡å‹è¿›è¡Œè¯†åˆ«
    const recognition = await recognizeImage(imageUrl, modelConfig, prompt);

    console.log(`âœ… è¯†åˆ«å®Œæˆ: ${fileId || imageUrl}`);

    return {
      statusCode: 200,
      headers,
      body: JSON.stringify({
        success: true,
        recognition: recognition,
        file: {
          id: fileId,
          url: imageUrl
        }
      })
    };

  } catch (error) {
    console.error('Recognition error:', error);
    
    return {
      statusCode: 500,
      headers,
      body: JSON.stringify({
        error: 'Recognition failed',
        message: error.message || 'å›¾ç‰‡è¯†åˆ«å¤±è´¥'
      })
    };
  }
};

// æ ¹æ®ä¸åŒçš„AIæ¨¡å‹æä¾›å•†è¿›è¡Œè¯†åˆ«
async function recognizeImage(imageUrl, modelConfig, prompt) {
  const { model, apiKey, apiUrl } = modelConfig;

  try {
    if (model.includes('gemini')) {
      return await recognizeWithGemini(imageUrl, modelConfig, prompt);
    } else if (model.includes('gpt') || model.includes('openai')) {
      return await recognizeWithOpenAI(imageUrl, modelConfig, prompt);
    } else if (model.includes('deepseek')) {
      return await recognizeWithDeepSeek(imageUrl, modelConfig, prompt);
    } else if (model.includes('claude')) {
      return await recognizeWithClaude(imageUrl, modelConfig, prompt);
    } else {
      return await recognizeWithGeneric(imageUrl, modelConfig, prompt);
    }
  } catch (error) {
    console.error('AI model recognition error:', error);
    throw new Error(`AIæ¨¡å‹è¯†åˆ«å¤±è´¥: ${error.message}`);
  }
}

// Geminiè¯†åˆ«
async function recognizeWithGemini(imageUrl, modelConfig, prompt) {
  const { model, apiKey, apiUrl } = modelConfig;
  
  // ä¸‹è½½å›¾ç‰‡å¹¶è½¬æ¢ä¸ºbase64
  const imageData = await downloadImageAsBase64(imageUrl);
  
  const requestBody = {
    contents: [
      {
        parts: [
          { text: prompt },
          {
            inlineData: {
              mimeType: "image/jpeg",
              data: imageData
            }
          }
        ]
      }
    ]
  };

  const response = await axiosInstance.post(
    `${apiUrl}/models/${model}:generateContent?key=${apiKey}`,
    requestBody,
    {
      headers: {
        'Content-Type': 'application/json'
      }
    }
  );

  const result = response.data.candidates[0].content.parts[0].text;
  
  return {
    content: result,
    confidence: 0.95, // Geminié€šå¸¸æœ‰è¾ƒé«˜çš„ç½®ä¿¡åº¦
    model: model,
    provider: 'gemini',
    timestamp: new Date().toISOString()
  };
}

// OpenAIè¯†åˆ«
async function recognizeWithOpenAI(imageUrl, modelConfig, prompt) {
  const { model, apiKey, apiUrl } = modelConfig;
  
  const requestBody = {
    model: model,
    messages: [
      {
        role: "user",
        content: [
          { type: "text", text: prompt },
          { type: "image_url", image_url: { url: imageUrl } }
        ]
      }
    ],
    max_tokens: 2000
  };

  const response = await axiosInstance.post(
    `${apiUrl}/chat/completions`,
    requestBody,
    {
      headers: {
        'Authorization': `Bearer ${apiKey}`,
        'Content-Type': 'application/json'
      }
    }
  );

  const result = response.data.choices[0].message.content;
  
  return {
    content: result,
    confidence: 0.92,
    model: model,
    provider: 'openai',
    timestamp: new Date().toISOString()
  };
}

// DeepSeekè¯†åˆ«
async function recognizeWithDeepSeek(imageUrl, modelConfig, prompt) {
  const { model, apiKey, apiUrl } = modelConfig;
  
  const requestBody = {
    model: model,
    messages: [
      {
        role: "user",
        content: [
          { type: "text", text: prompt },
          { type: "image_url", image_url: { url: imageUrl } }
        ]
      }
    ]
  };

  const response = await axiosInstance.post(
    `${apiUrl}/chat/completions`,
    requestBody,
    {
      headers: {
        'Authorization': `Bearer ${apiKey}`,
        'Content-Type': 'application/json'
      }
    }
  );

  const result = response.data.choices[0].message.content;
  
  return {
    content: result,
    confidence: 0.90,
    model: model,
    provider: 'deepseek',
    timestamp: new Date().toISOString()
  };
}

// Claudeè¯†åˆ«
async function recognizeWithClaude(imageUrl, modelConfig, prompt) {
  const { model, apiKey, apiUrl } = modelConfig;
  
  // ä¸‹è½½å›¾ç‰‡å¹¶è½¬æ¢ä¸ºbase64
  const imageData = await downloadImageAsBase64(imageUrl);
  
  const requestBody = {
    model: model,
    max_tokens: 2000,
    messages: [
      {
        role: "user",
        content: [
          { type: "text", text: prompt },
          {
            type: "image",
            source: {
              type: "base64",
              media_type: "image/jpeg",
              data: imageData
            }
          }
        ]
      }
    ]
  };

  const response = await axiosInstance.post(
    `${apiUrl}/messages`,
    requestBody,
    {
      headers: {
        'x-api-key': apiKey,
        'Content-Type': 'application/json',
        'anthropic-version': '2023-06-01'
      }
    }
  );

  const result = response.data.content[0].text;
  
  return {
    content: result,
    confidence: 0.93,
    model: model,
    provider: 'claude',
    timestamp: new Date().toISOString()
  };
}

// é€šç”¨è¯†åˆ«ï¼ˆé€‚ç”¨äºOpenAIå…¼å®¹æ¥å£ï¼‰
async function recognizeWithGeneric(imageUrl, modelConfig, prompt) {
  const { model, apiKey, apiUrl } = modelConfig;
  
  const requestBody = {
    model: model,
    messages: [
      {
        role: "user",
        content: [
          { type: "text", text: prompt },
          { type: "image_url", image_url: { url: imageUrl } }
        ]
      }
    ],
    max_tokens: 2000
  };

  const response = await axiosInstance.post(
    `${apiUrl}/chat/completions`,
    requestBody,
    {
      headers: {
        'Authorization': `Bearer ${apiKey}`,
        'Content-Type': 'application/json'
      }
    }
  );

  const result = response.data.choices[0].message.content;
  
  return {
    content: result,
    confidence: 0.85,
    model: model,
    provider: 'generic',
    timestamp: new Date().toISOString()
  };
}

// ä¸‹è½½å›¾ç‰‡å¹¶è½¬æ¢ä¸ºbase64
async function downloadImageAsBase64(imageUrl) {
  // ç¡®ä¿åœ¨Netlifyç¯å¢ƒä¸­ä¸ä½¿ç”¨ä»£ç†
  const config = {
    responseType: 'arraybuffer',
    timeout: 30000,
    maxRedirects: 5
  };
  
  // æ˜ç¡®ç¦ç”¨ä»£ç†ï¼ˆNetlify Functionsåº”ç›´æ¥è¿æ¥ï¼‰
  if (process.env.NETLIFY || process.env.CONTEXT || process.env.DEPLOY_URL) {
    config.proxy = false;
    console.log('ğŸš« Netlify environment - proxy disabled for image download');
  }
  
  const response = await axiosInstance.get(imageUrl, config);
  const base64 = Buffer.from(response.data).toString('base64');
  return base64;
}